{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This adds dummy train names for any trains that are missing them\n",
    "def fill_train_ids(df):\n",
    "    df = df.copy()\n",
    "    n = 0 #For paired trains\n",
    "    m = 0 #For single trains\n",
    "    for i, val in df.iloc[1].iteritems():\n",
    "        #If we have no train name (i.e. it's a NaN):\n",
    "        if i > 1 and val != val:\n",
    "            #If we have that 'to future column' arrow...\n",
    "            if (df.iloc[:,i].str.strip() == '↳').any():\n",
    "                #Set dummy train ID\n",
    "                df.at[1, i] = 'pair_' + str(n)\n",
    "            #If we have that 'from past column' arrow...\n",
    "            elif (df.iloc[:,i].str.strip() == '↴').any():\n",
    "                #Set dummy train ID\n",
    "                df.at[1, i] = 'pair_' + str(n)\n",
    "                #Advance n to get a new dummy train ID\n",
    "                n += 1\n",
    "            #This is a single train\n",
    "            else:\n",
    "                #Set dummy train ID\n",
    "                df.at[1, i] = 'single_' + str(m)\n",
    "                m += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This sets the top two rows a column names\n",
    "def set_column_names(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    #Combine top two rows into one row\n",
    "    df.loc[-1] = df.iloc[0] + ' ' + df.iloc[1]\n",
    "    df.sort_index(inplace=True)  # sorting by index\n",
    "    \n",
    "    #Fix column names for variables\n",
    "    df.iloc[0,0] = 'km'\n",
    "    df.iloc[0,1] = 'station'\n",
    "    \n",
    "    #Set column names\n",
    "    df = df.rename(columns=df.iloc[0]).drop(df.index[0]).reset_index(drop=True)\n",
    "    \n",
    "    #Drop top two rows\n",
    "    df.drop(df.index[0:2], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This converts the time column to minutes since midnight\n",
    "def convert_times(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    #Create hr and min columns\n",
    "    df['hr'], df['min'] = df['time'].str.strip()\\\n",
    "        .str.replace('|', '')\\\n",
    "        .str.replace('↳', '')\\\n",
    "        .str.replace('↴', '')\\\n",
    "        .str.replace('o', '')\\\n",
    "        .str.split(':').str\n",
    "\n",
    "    #Tweak times after midnight\n",
    "    df.loc[df['hr'] == '0', ['hr']] = 24\n",
    "    df.loc[df['hr'] == '1', ['hr']] = 25\n",
    "\n",
    "    #Replace blanks with NaNs so we can convert to float\n",
    "    df.loc[df['hr'] == '', ['hr']] = np.NaN\n",
    "\n",
    "    #Calculate time in minutes\n",
    "    df['time'] = df['hr'].astype(float)*60 + df['min'].astype(float)\n",
    "\n",
    "    #Drop hr and min\n",
    "    df.drop(columns=['hr', 'min'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/1-WeekdaySchedule/HighNB-Table1.csv...\n",
      "Loading ../data/1-WeekdaySchedule/ModerateNB-Table1.csv...\n",
      "Loading ../data/1-WeekdaySchedule/BaselineSB-Table1.csv...\n",
      "Loading ../data/1-WeekdaySchedule/BaselineNB-Table1.csv...\n",
      "Loading ../data/1-WeekdaySchedule/HighSB-Table1.csv...\n",
      "Loading ../data/1-WeekdaySchedule/ModerateSB-Table1.csv...\n"
     ]
    }
   ],
   "source": [
    "#Load all schedules and process\n",
    "schedules = glob.glob('../data/1-WeekdaySchedule/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in schedules:\n",
    "    print('Loading {}...'.format(filename))\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "\n",
    "    df = fill_train_ids(df)\n",
    "\n",
    "    df = set_column_names(df)\n",
    "    \n",
    "    #San Jose is double-entered in some timetables; drop one of them by dropping rows where km is NaN\n",
    "    df = df[(df['km'] == df['km'])]\n",
    "    \n",
    "    #Unpivot table\n",
    "    df = df.melt(id_vars=['km', 'station'], var_name='train_id', value_name='time')\n",
    "    \n",
    "    df = convert_times(df)\n",
    "    \n",
    "    #Remove rows where time column is NaN (train does not stop)\n",
    "    df = df[df['time'] == df['time']].reset_index(drop=True)\n",
    "    \n",
    "    #Set scenario name\n",
    "    df['scenario'] = filename.split('/')[3].split('-')[0]\n",
    "    \n",
    "    li.append(df)\n",
    "\n",
    "df_final = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../data/parsed_data/schedules/all_schedules_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
